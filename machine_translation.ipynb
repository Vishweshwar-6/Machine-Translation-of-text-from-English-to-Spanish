{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the necessary libraries."
      ],
      "metadata": {
        "id": "iXl57fM9Gznt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XOo9YFpH3mt"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from string import digits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the path to the dataset"
      ],
      "metadata": {
        "id": "J9xvLhQdHHL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"spa.txt\""
      ],
      "metadata": {
        "id": "OEoI6dUCH6bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the dataset from .txt to a dataframe with column names as \"source\", \"target\", \"comments\""
      ],
      "metadata": {
        "id": "b5XcA51THLvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data\n",
        "lines_raw= pd.read_table(data_path,names=['source', 'target', 'comments'])\n",
        "lines_raw.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dj8HiFosIIss",
        "outputId": "f1ba6a17-fc8a-49cf-e5f3-4221fcfb081a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   source  \\\n",
              "74504      The children have glow sticks.   \n",
              "90545  I haven't been sleeping that well.   \n",
              "66763        You have a beautiful family.   \n",
              "40662             These ties aren't mine.   \n",
              "57908         He is twice as old as I am.   \n",
              "\n",
              "                                       target  \\\n",
              "74504     Los niños tienen palos que brillan.   \n",
              "90545  No he estado durmiendo demasiado bien.   \n",
              "66763              Tenés una hermosa familia.   \n",
              "40662             Estas corbatas no son mías.   \n",
              "57908         Él es el doble de viejo que yo.   \n",
              "\n",
              "                                                comments  \n",
              "74504  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "90545  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
              "66763  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "40662  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "57908  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-327146e5-30fe-44ad-baf4-cd1815853144\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74504</th>\n",
              "      <td>The children have glow sticks.</td>\n",
              "      <td>Los niños tienen palos que brillan.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90545</th>\n",
              "      <td>I haven't been sleeping that well.</td>\n",
              "      <td>No he estado durmiendo demasiado bien.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66763</th>\n",
              "      <td>You have a beautiful family.</td>\n",
              "      <td>Tenés una hermosa familia.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40662</th>\n",
              "      <td>These ties aren't mine.</td>\n",
              "      <td>Estas corbatas no son mías.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57908</th>\n",
              "      <td>He is twice as old as I am.</td>\n",
              "      <td>Él es el doble de viejo que yo.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-327146e5-30fe-44ad-baf4-cd1815853144')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-327146e5-30fe-44ad-baf4-cd1815853144 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-327146e5-30fe-44ad-baf4-cd1815853144');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Standard text preprocessing to clear up\n",
        "the sentences of extra spaces and converting special characters to \"\\1\".\n",
        "2. Adding \"start_\" and \"_end\" to the sentences for ease of conversion to tensors."
      ],
      "metadata": {
        "id": "sogUFJMpHetY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
        "    num_digits= str.maketrans('','', digits)\n",
        "\n",
        "    sentence= sentence.lower()\n",
        "    sentence= re.sub(\" +\", \" \", sentence)\n",
        "    sentence= re.sub(\"'\", '', sentence)\n",
        "    sentence= sentence.translate(num_digits)\n",
        "    sentence= sentence.strip()\n",
        "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.rstrip().strip()\n",
        "    sentence=  'start_ ' + sentence + ' _end'\n",
        "\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "eeBgYIx7ILRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentence = u\"it looks good\"\n",
        "print(preprocess_sentence(english_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_B1jp82IeGF",
        "outputId": "6ad67b22-c265-417a-abf1-1c859885c7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_ it looks good _end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remove the accents\n",
        "2. Clean the sentences\n",
        "3. Return word pairs in the format: [ENGLISH, SPANISH]"
      ],
      "metadata": {
        "id": "lUnXWkL9JTCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(path, number_of_rows):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:number_of_rows]]\n",
        "  print(path)\n",
        "  return zip(*word_pairs)"
      ],
      "metadata": {
        "id": "y_cA27h7Ign7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size=60000\n",
        "source, target, comments = create_dataset(data_path, sample_size)\n",
        "print(source[-20])\n",
        "print(target[-20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_do32CCvIth0",
        "outputId": "18968e27-b10c-4ff3-dfcb-a1c0cce35c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spa.txt\n",
            "start_ tell tom i dont know mary . _end\n",
            "start_ decile a tomás que yo no conozco a maría . _end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for getting the max of length of the input tensors."
      ],
      "metadata": {
        "id": "z6pqozOyLP1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "metadata": {
        "id": "XVbAInGzIzYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are creating the tensors for source sentences using inbuilt methods in Keras and then padding them to make them of equal length for ease of feed to encoders."
      ],
      "metadata": {
        "id": "eEw50EiIL83d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_sentence_tokenizer.fit_on_texts(source)\n",
        "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
        "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
      ],
      "metadata": {
        "id": "P0e_FJ9UI7Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same thing as above for target sentences"
      ],
      "metadata": {
        "id": "gDt3rLggMfBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_sentence_tokenizer.fit_on_texts(target)\n",
        "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
        "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )"
      ],
      "metadata": {
        "id": "6F81zQfHI9E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_target_length= max(len(t) for t in  target_tensor)\n",
        "print(max_target_length)\n",
        "max_source_length= max(len(t) for t in  source_tensor)\n",
        "print(max_source_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_repcPvI_xb",
        "outputId": "79bdfe8a-5fca-432e-ccf6-ef5c6a59b776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the traing test split."
      ],
      "metadata": {
        "id": "6fGu461zNEzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
      ],
      "metadata": {
        "id": "6Rts_tKhJDoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX1EY1utJHZb",
        "outputId": "b046a173-313c-4532-9659-cc6a7bc4479a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000 48000 12000 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(input_tensor_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ODmj-SiJJ4L",
        "outputId": "c54dca42-7064-4d7c-e8fa-31d529680beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "metadata": {
        "id": "CJvNMAHXJL6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert( target_sentence_tokenizer, target_train_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW0YGN87JOBj",
        "outputId": "668f0ef9-a57c-44ea-8a99-0b65e5cd0909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> start_\n",
            "9 ----> is\n",
            "16 ----> this\n",
            "26 ----> what\n",
            "7 ----> tom\n",
            "219 ----> wanted\n",
            "6 ----> ?\n",
            "2 ----> _end\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> start_\n",
            "5 ----> ¿\n",
            "8 ----> es\n",
            "17 ----> lo\n",
            "12 ----> que\n",
            "152 ----> quería\n",
            "60 ----> tomás\n",
            "4 ----> ?\n",
            "2 ----> _end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(source_train_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "type(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW7Aa4tJJQxb",
        "outputId": "310729de-8871-4327-fe4b-e6a6aff657bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpAoNxPBJZFq",
        "outputId": "7c32084c-7ac4-4e38-f2fa-2d695b3ced66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 12]), TensorShape([64, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "1S12umgdJdBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBSpvNkRJgTD",
        "outputId": "e591dbb3-d633-4dcd-f2ae-8addf168992e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 12, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "fktnYg3QJjAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI-2G9XRJnJi",
        "outputId": "67a87914-0db5-49a6-b24e-ed0802b09abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "knBTz5IqJpq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RvP4SX1Juz7",
        "outputId": "d97b35a6-2d20-4bff-91cb-3c35c0bf562e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 15217)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "sV6TqaHwJywr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "metadata": {
        "id": "BszklcRyJ1rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "pkENZxuVJ4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrOVU25hJ8Ly",
        "outputId": "04497ca0-9dd6-4c84-8e7d-38ab41f7cd23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
        "\n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw44vfJpJ-zb",
        "outputId": "f76feca8-abe1-4d3f-e299-b3c9964c61f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 loss 3.6208295822143555\n",
            "Epoch 1 Batch 100 loss 1.855496883392334\n",
            "Epoch 1 Batch 200 loss 1.7929606437683105\n",
            "Epoch 1 Batch 300 loss 1.7297073602676392\n",
            "Epoch 1 Batch 400 loss 1.6636979579925537\n",
            "Epoch 1 Batch 500 loss 1.570885181427002\n",
            "Epoch 1 Batch 600 loss 1.3450454473495483\n",
            "Epoch 1 Batch 700 loss 1.3277475833892822\n",
            "Epoch 1 Loss 1.6594\n",
            "Time taken for 1 epoch 121.26847505569458 sec\n",
            "\n",
            "Epoch 2 Batch 0 loss 1.0069832801818848\n",
            "Epoch 2 Batch 100 loss 1.0698715448379517\n",
            "Epoch 2 Batch 200 loss 1.0061531066894531\n",
            "Epoch 2 Batch 300 loss 1.0801366567611694\n",
            "Epoch 2 Batch 400 loss 0.9677174091339111\n",
            "Epoch 2 Batch 500 loss 0.7767098546028137\n",
            "Epoch 2 Batch 600 loss 0.8772211670875549\n",
            "Epoch 2 Batch 700 loss 0.8196144700050354\n",
            "Epoch 2 Loss 0.9933\n",
            "Time taken for 1 epoch 98.71511578559875 sec\n",
            "\n",
            "Epoch 3 Batch 0 loss 0.7009827494621277\n",
            "Epoch 3 Batch 100 loss 0.7041088938713074\n",
            "Epoch 3 Batch 200 loss 0.5786744356155396\n",
            "Epoch 3 Batch 300 loss 0.6698490381240845\n",
            "Epoch 3 Batch 400 loss 0.6271928548812866\n",
            "Epoch 3 Batch 500 loss 0.6421031951904297\n",
            "Epoch 3 Batch 600 loss 0.6068242788314819\n",
            "Epoch 3 Batch 700 loss 0.5892572402954102\n",
            "Epoch 3 Loss 0.6508\n",
            "Time taken for 1 epoch 97.44628572463989 sec\n",
            "\n",
            "Epoch 4 Batch 0 loss 0.49306488037109375\n",
            "Epoch 4 Batch 100 loss 0.4648939371109009\n",
            "Epoch 4 Batch 200 loss 0.456551194190979\n",
            "Epoch 4 Batch 300 loss 0.4165707230567932\n",
            "Epoch 4 Batch 400 loss 0.41162753105163574\n",
            "Epoch 4 Batch 500 loss 0.5062589049339294\n",
            "Epoch 4 Batch 600 loss 0.4384058713912964\n",
            "Epoch 4 Batch 700 loss 0.5117796659469604\n",
            "Epoch 4 Loss 0.4518\n",
            "Time taken for 1 epoch 98.72113037109375 sec\n",
            "\n",
            "Epoch 5 Batch 0 loss 0.2859765887260437\n",
            "Epoch 5 Batch 100 loss 0.2971532344818115\n",
            "Epoch 5 Batch 200 loss 0.3200015425682068\n",
            "Epoch 5 Batch 300 loss 0.34482577443122864\n",
            "Epoch 5 Batch 400 loss 0.2841174006462097\n",
            "Epoch 5 Batch 500 loss 0.330680251121521\n",
            "Epoch 5 Batch 600 loss 0.283058762550354\n",
            "Epoch 5 Batch 700 loss 0.27723875641822815\n",
            "Epoch 5 Loss 0.3297\n",
            "Time taken for 1 epoch 97.3855721950531 sec\n",
            "\n",
            "Epoch 6 Batch 0 loss 0.267638623714447\n",
            "Epoch 6 Batch 100 loss 0.2548615336418152\n",
            "Epoch 6 Batch 200 loss 0.2995065748691559\n",
            "Epoch 6 Batch 300 loss 0.26721474528312683\n",
            "Epoch 6 Batch 400 loss 0.24386568367481232\n",
            "Epoch 6 Batch 500 loss 0.22026395797729492\n",
            "Epoch 6 Batch 600 loss 0.3131471276283264\n",
            "Epoch 6 Batch 700 loss 0.25862953066825867\n",
            "Epoch 6 Loss 0.2524\n",
            "Time taken for 1 epoch 98.70611810684204 sec\n",
            "\n",
            "Epoch 7 Batch 0 loss 0.2133409082889557\n",
            "Epoch 7 Batch 100 loss 0.21582823991775513\n",
            "Epoch 7 Batch 200 loss 0.1824369728565216\n",
            "Epoch 7 Batch 300 loss 0.1758970022201538\n",
            "Epoch 7 Batch 400 loss 0.18593303859233856\n",
            "Epoch 7 Batch 500 loss 0.21298378705978394\n",
            "Epoch 7 Batch 600 loss 0.2658042013645172\n",
            "Epoch 7 Batch 700 loss 0.22319330275058746\n",
            "Epoch 7 Loss 0.2047\n",
            "Time taken for 1 epoch 97.54214668273926 sec\n",
            "\n",
            "Epoch 8 Batch 0 loss 0.12934672832489014\n",
            "Epoch 8 Batch 100 loss 0.12738735973834991\n",
            "Epoch 8 Batch 200 loss 0.174077570438385\n",
            "Epoch 8 Batch 300 loss 0.14805588126182556\n",
            "Epoch 8 Batch 400 loss 0.18592575192451477\n",
            "Epoch 8 Batch 500 loss 0.18206167221069336\n",
            "Epoch 8 Batch 600 loss 0.16003838181495667\n",
            "Epoch 8 Batch 700 loss 0.21326395869255066\n",
            "Epoch 8 Loss 0.1713\n",
            "Time taken for 1 epoch 98.7116973400116 sec\n",
            "\n",
            "Epoch 9 Batch 0 loss 0.11004060506820679\n",
            "Epoch 9 Batch 100 loss 0.1209753155708313\n",
            "Epoch 9 Batch 200 loss 0.12305767834186554\n",
            "Epoch 9 Batch 300 loss 0.12427322566509247\n",
            "Epoch 9 Batch 400 loss 0.14409616589546204\n",
            "Epoch 9 Batch 500 loss 0.19492356479167938\n",
            "Epoch 9 Batch 600 loss 0.17810209095478058\n",
            "Epoch 9 Batch 700 loss 0.1637606918811798\n",
            "Epoch 9 Loss 0.1485\n",
            "Time taken for 1 epoch 97.11901617050171 sec\n",
            "\n",
            "Epoch 10 Batch 0 loss 0.12758633494377136\n",
            "Epoch 10 Batch 100 loss 0.10212334990501404\n",
            "Epoch 10 Batch 200 loss 0.11917568743228912\n",
            "Epoch 10 Batch 300 loss 0.1319488137960434\n",
            "Epoch 10 Batch 400 loss 0.13021883368492126\n",
            "Epoch 10 Batch 500 loss 0.12025248259305954\n",
            "Epoch 10 Batch 600 loss 0.11068035662174225\n",
            "Epoch 10 Batch 700 loss 0.12829898297786713\n",
            "Epoch 10 Loss 0.1333\n",
            "Time taken for 1 epoch 98.56459140777588 sec\n",
            "\n",
            "Epoch 11 Batch 0 loss 0.09421756863594055\n",
            "Epoch 11 Batch 100 loss 0.09087371826171875\n",
            "Epoch 11 Batch 200 loss 0.12508603930473328\n",
            "Epoch 11 Batch 300 loss 0.11063015460968018\n",
            "Epoch 11 Batch 400 loss 0.11267341673374176\n",
            "Epoch 11 Batch 500 loss 0.1387728452682495\n",
            "Epoch 11 Batch 600 loss 0.1392289102077484\n",
            "Epoch 11 Batch 700 loss 0.12773147225379944\n",
            "Epoch 11 Loss 0.1208\n",
            "Time taken for 1 epoch 97.43216371536255 sec\n",
            "\n",
            "Epoch 12 Batch 0 loss 0.11333970725536346\n",
            "Epoch 12 Batch 100 loss 0.1087932363152504\n",
            "Epoch 12 Batch 200 loss 0.0776815116405487\n",
            "Epoch 12 Batch 300 loss 0.11460807919502258\n",
            "Epoch 12 Batch 400 loss 0.09922212362289429\n",
            "Epoch 12 Batch 500 loss 0.13565640151500702\n",
            "Epoch 12 Batch 600 loss 0.13679321110248566\n",
            "Epoch 12 Batch 700 loss 0.13276301324367523\n",
            "Epoch 12 Loss 0.1114\n",
            "Time taken for 1 epoch 98.7868549823761 sec\n",
            "\n",
            "Epoch 13 Batch 0 loss 0.09774134308099747\n",
            "Epoch 13 Batch 100 loss 0.07620439678430557\n",
            "Epoch 13 Batch 200 loss 0.08305118978023529\n",
            "Epoch 13 Batch 300 loss 0.09381866455078125\n",
            "Epoch 13 Batch 400 loss 0.0780705139040947\n",
            "Epoch 13 Batch 500 loss 0.13532891869544983\n",
            "Epoch 13 Batch 600 loss 0.1342727094888687\n",
            "Epoch 13 Batch 700 loss 0.10633742064237595\n",
            "Epoch 13 Loss 0.1041\n",
            "Time taken for 1 epoch 97.50460481643677 sec\n",
            "\n",
            "Epoch 14 Batch 0 loss 0.09504389762878418\n",
            "Epoch 14 Batch 100 loss 0.0904066413640976\n",
            "Epoch 14 Batch 200 loss 0.09760436415672302\n",
            "Epoch 14 Batch 300 loss 0.08720933645963669\n",
            "Epoch 14 Batch 400 loss 0.1181563287973404\n",
            "Epoch 14 Batch 500 loss 0.12498718500137329\n",
            "Epoch 14 Batch 600 loss 0.10926707088947296\n",
            "Epoch 14 Batch 700 loss 0.11980807036161423\n",
            "Epoch 14 Loss 0.0990\n",
            "Time taken for 1 epoch 98.62852454185486 sec\n",
            "\n",
            "Epoch 15 Batch 0 loss 0.05970267206430435\n",
            "Epoch 15 Batch 100 loss 0.061071161180734634\n",
            "Epoch 15 Batch 200 loss 0.07549681514501572\n",
            "Epoch 15 Batch 300 loss 0.07342039048671722\n",
            "Epoch 15 Batch 400 loss 0.11697639524936676\n",
            "Epoch 15 Batch 500 loss 0.09588910639286041\n",
            "Epoch 15 Batch 600 loss 0.12118574976921082\n",
            "Epoch 15 Batch 700 loss 0.10362313687801361\n",
            "Epoch 15 Loss 0.0960\n",
            "Time taken for 1 epoch 97.51848220825195 sec\n",
            "\n",
            "Epoch 16 Batch 0 loss 0.08676862716674805\n",
            "Epoch 16 Batch 100 loss 0.09143759310245514\n",
            "Epoch 16 Batch 200 loss 0.09311921894550323\n",
            "Epoch 16 Batch 300 loss 0.07676206529140472\n",
            "Epoch 16 Batch 400 loss 0.135639488697052\n",
            "Epoch 16 Batch 500 loss 0.08140682429075241\n",
            "Epoch 16 Batch 600 loss 0.11014790087938309\n",
            "Epoch 16 Batch 700 loss 0.09852355718612671\n",
            "Epoch 16 Loss 0.0922\n",
            "Time taken for 1 epoch 98.70222735404968 sec\n",
            "\n",
            "Epoch 17 Batch 0 loss 0.05231650173664093\n",
            "Epoch 17 Batch 100 loss 0.07782743871212006\n",
            "Epoch 17 Batch 200 loss 0.0886944830417633\n",
            "Epoch 17 Batch 300 loss 0.06645612418651581\n",
            "Epoch 17 Batch 400 loss 0.08131374418735504\n",
            "Epoch 17 Batch 500 loss 0.0698828250169754\n",
            "Epoch 17 Batch 600 loss 0.10666253417730331\n",
            "Epoch 17 Batch 700 loss 0.13103674352169037\n",
            "Epoch 17 Loss 0.0875\n",
            "Time taken for 1 epoch 97.49698567390442 sec\n",
            "\n",
            "Epoch 18 Batch 0 loss 0.06494007259607315\n",
            "Epoch 18 Batch 100 loss 0.06904837489128113\n",
            "Epoch 18 Batch 200 loss 0.09586364030838013\n",
            "Epoch 18 Batch 300 loss 0.08590534329414368\n",
            "Epoch 18 Batch 400 loss 0.08063644170761108\n",
            "Epoch 18 Batch 500 loss 0.07809185236692429\n",
            "Epoch 18 Batch 600 loss 0.09519553929567337\n",
            "Epoch 18 Batch 700 loss 0.0905570536851883\n",
            "Epoch 18 Loss 0.0833\n",
            "Time taken for 1 epoch 98.63182830810547 sec\n",
            "\n",
            "Epoch 19 Batch 0 loss 0.07842577993869781\n",
            "Epoch 19 Batch 100 loss 0.05124466121196747\n",
            "Epoch 19 Batch 200 loss 0.07407447695732117\n",
            "Epoch 19 Batch 300 loss 0.07577839493751526\n",
            "Epoch 19 Batch 400 loss 0.07991451025009155\n",
            "Epoch 19 Batch 500 loss 0.09439082443714142\n",
            "Epoch 19 Batch 600 loss 0.09449760615825653\n",
            "Epoch 19 Batch 700 loss 0.10333232581615448\n",
            "Epoch 19 Loss 0.0816\n",
            "Time taken for 1 epoch 97.4860532283783 sec\n",
            "\n",
            "Epoch 20 Batch 0 loss 0.06502152979373932\n",
            "Epoch 20 Batch 100 loss 0.05755830556154251\n",
            "Epoch 20 Batch 200 loss 0.04166742041707039\n",
            "Epoch 20 Batch 300 loss 0.07643771916627884\n",
            "Epoch 20 Batch 400 loss 0.06846320629119873\n",
            "Epoch 20 Batch 500 loss 0.08903177082538605\n",
            "Epoch 20 Batch 600 loss 0.09987042844295502\n",
            "Epoch 20 Batch 700 loss 0.09722450375556946\n",
            "Epoch 20 Loss 0.0795\n",
            "Time taken for 1 epoch 98.87877774238586 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  #print(sentence)\n",
        "  #print(source_sentence_tokenizer.word_index)\n",
        "\n",
        "  inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_source_length,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
        "\n",
        "  for t in range(max_target_length):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "C34qRSi8KCzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "De-psr65RsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "qtGcvJt-RvDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgiEbGdiRyKr",
        "outputId": "4cdca497-f242-4681-86b9-d87d7a66b08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff3b6aadac0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'I said hello to her.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "9ndmL01ZR1AL",
        "outputId": "7f8ca3a6-808d-4f40-ba59-bc023e809a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: start_ i said hello to her . _end\n",
            "Predicted translation: dije a ella . _end \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMVtm82QR31z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PaIHRpVhKyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}